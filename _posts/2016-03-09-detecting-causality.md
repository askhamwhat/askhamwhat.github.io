---
layout: post
title: "Journal club: Detecting causality in complex ecosystems"
date: 2016-03-09
tags:
  - math
  - review
  - dynamical systems
---

For the [Kutz research group journal club](http://faculty.washington.edu/kutz/page5/page20/),
I prepared some notes on the paper "Detecting causality in complex 
ecosystems" by Sugihara et al. The paper and supplementary materials 
can be found at the 
[Science magazine website](http://science.sciencemag.org/content/338/6106/496).
It is remarkably clear and informative for an article in the brief *Science* format.
I recommend the original article and
supplementary materials for a deeper understanding of the 
convergent cross mapping (CCM) methodology. The Sugihara 
group also has a number of YouTube videos on the topic, some of which are
linked to below. My goal here is to outline the main ideas
from my perspective and to offer my take-aways. I also provide 
some simple MatLab scripts which replicate experiments from the article.

#### Setting

> Correlation does not necessarily imply 
> causation. 

The authors of "Detecting causality ..." credit
this maxim to Bishop Berkeley and his *A Treatise Concerning
the Principles of Human Knowledge* (1710) --- whether or not this
is the correct attribution, the idea is certainly old
and generally well-accepted. Indeed, it is rather 
straightforward to find evidence of the
danger in linking correlation to causation. 
Despite the high correlation coefficient, few would claim
that the divorce rate in Maine *causes* per capita margarine
consumption. For more examples, see the strongest 
modern proponent of the maxim, 
[Tyler Vigen](http://tylervigen.com/spurious-correlations).

It turns out that the relationship between correlation and 
causation is particularly nebulous in the dynamical
systems setting. To be concrete, we say that two variables are 
causally linked if they come from the same dynamical system
(we will discuss one-way causation further down). 
Consider the dynamical system given by 

$$ \begin{array}{rl} X(t+1) &= X(t) ( r_x - r_x X(t) - \beta_{xy} Y(t)) \\
   Y(t+1) &= Y(t) ( r_y - r_y Y(t) - \beta_{yx} X(t)) \end{array} . $$

The variables \\(X\\) and \\(Y\\) are causally linked when \\(\beta_{xy} > 0\\) 
and \\( \beta_{yx} > 0 \\). But for a long enough simulation, it is possible 
to find time windows where this system appears correlated, anti-correlated, and
uncorrelated. The image below (a recreation of figure 1
from the paper) shows example windows of 
length 20 which are generated by a single run of the
system (the first plot shows the correlation coefficient
for a window of length 20 as you vary the starting point).

<img src="/post_resources/images/correlation-mirage.png" 
     alt="correlation mirage" width="100%" />

The code used to generate this plot can be found
[here](/post_resources/code/fig1code.m). The phenomena
shown above are referred to as "mirage correlations"
and demonstrate that the correlation coefficient is not
related at all to causation for such systems. 
For dynamical systems, even the lack of correlation 
does not imply a lack of causation.

Fortunately, correlation is not the only known
test for cause. The concept of 
[Granger causality](https://en.wikipedia.org/wiki/Granger_causality)
comes from the field of economics and is a test of 
"predictive causality" for stochastic systems.
In brief, a variable \\(X\\) is said to Granger
cause \\(Y\\) if the prior information of 
\\(X\\) improves predictions of the future behavior
of \\(Y\\). This has proved a powerful tool for
stochastic systems and earned Granger a Nobel prize.
Unfortunately, Granger causality is
quite distinct from the notion of causality 
that is natural in the dynamical systems setting. Granger
causality assumes that the cause contains unique
information about the future state of the effect,
which is not true of variables from the 
same dynamical system.
In the supplementary materials, Sugihara et al. 
demonstrate that the tools of Granger
causality give erroneous results when applied
to the examples of the main paper.
As an alternative, the authors introduce
convergent cross mapping (CCM), a
framework for determining causality in dynamical
systems.

#### CCM Theory

The theoretical foundation of CCM is [Takens'
theorem](https://en.wikipedia.org/wiki/Takens%27_theorem).
The result is rather technical but implies that
the time series for one observed variable of the
dynamical system can be used to reconstruct
essential properties of the original system. For 
CCM, this is accomplished by contructing a "shadow
manifold" using the time series of an observed
variable. The shadow manifold is given by 
vectors of the form \\(\vec{X}(t) = (X(t),X(t-\tau),
\ldots , X(t-(m-1)\tau)) \\), consisting of
lagged copies of \\(X\\). For sufficiently
large \\(m\\), the shadow manifold is diffeomorphic
to the strange attractor of the original system
(supposing that the dynamics live on a strange attractor).
These ideas are illustrated in the video below.

{% include youtube.html youtube_id="rs3gYeZeJcw" %}

If two variables \\(X\\) and \\(Y\\) both come
from the same dynamical system, then their corresponding
shadow manifolds should be diffeomorphic (there are some 
exceptions to this). Therefore, nearby points on the
\\(X\\) shadow manifold should correspond to 
nearby points on the \\(Y\\) shadow manifold. CCM
is based on using this property to make predictions
of the state of \\(Y\\) using the shadow manifold of \\(X\\)
and vice-versa. A nice feature of CCM is that, with
more and more observations of the system, the
shadow manifolds become better resolved and the prediction
generated from this procedure would become more 
accurate in the case that \\(X\\)
and \\(Y\\) are causally linked. The following video
demonstrates these ideas.

{% include youtube.html youtube_id="NrFdIz-D2yM" %}

#### CCM Algorithm

Much of the analysis in the CCM framework is based on
the ability to use the shadow manifold of one variable
to make a prediction of another. The quality of this 
prediction can then be used as the basis for a number
of tests. We outline the procedure of producing an approximation
to \\(Y(t)\\) from the shadow manifold of \\(X\\).
Let \\( \{ X(1), \ldots, X(L) \} \\) and 
\\( \{ Y(1), \ldots, Y(L) \} \\) be given. 

1. Construct a shadow manifold of dimension \\(m\\) by simply
   forming the set 

   $$ M_X = \{ \vec{X}(t) = (X(t),X(t-1),\ldots,X(t-(m-1)) ): t = m, \ldots, L \} . $$

2. For a given time \\(t\\), compute the \\(m+1\\) nearest neighbors
   of \\(\vec{X}(t)\\) (excluding \\(\vec{X}(t)\\) itself). Let
   the times corresponding to these points be \\(t_1, \ldots, t_{m+1} \\).
   
3. Compute the approximation \\(\hat{Y}(t) | M_X\\) as a weighted sum
   of the \\(Y(t_1),\ldots, Y(t_{m+1})\\). 

The paper calls for a specific weighting to be used
(see the supplement for details) but I suspect other weightings
may work as well. The details of how to choose an appropriate
dimension \\(m\\) for the shadow manifold are largely left out.
For the examples, it seems that the dimension was determined by 
starting with some initial guess and increasing until the predictions
stopped improving (the Whitney embedding theorem provides an
upper bound for this process).

#### CCM Style Analysis --- Synthetic Data

Here we present some of the examples from the paper
in which the CCM methodology is applied to synthetic data.
Both examples are based on the dynamical system given
above, i.e.

$$ \begin{array}{rl} X(t+1) &= X(t) ( r_x - r_x X(t) - \beta_{xy} Y(t)) \\
   Y(t+1) &= Y(t) ( r_y - r_y Y(t) - \beta_{yx} X(t)) \end{array} . $$

The dimension of the shadow manifolds was taken
to be \\(m=2\\).

1. **An example with bidirectional causality**. We consider
   the case where \\(\beta_{xy}\\) and \\(\beta_{yx}\\)
   are both positive and \\(\beta_{yx} \gg \beta_{xy} \\)
   (\\(r_x\\) and \\(r_y\\) are comparable).
   In this case, both variables are mutually coupled
   and the signal of \\(X\\) has a stronger influence
   on \\(Y\\) than \\(Y\\) has on \\(X\\). We perform
   simulations of the system of various lengths
   \\(L\\) and plot the quality of the predictions
   using shadow manifolds as a function of \\(L\\)
   in the image below. 

   <img src="/post_resources/images/bidirectional_coupling.png" 
   	  alt="bidirectional coupling" width="100%" />
   

   Because the scheme is convergent, we expect
   that the predictions become more accurate as \\(L\\)
   increases and this is what is seen. Moreover,
   the predictions for the variable \\(X\\) given the
   shadow manifold \\(M_Y\\) are observed to converge
   at a faster rate. This property appears generic and
   Sugihara et al. suggest that relative convergence
   rates could be used to determine the relative strengths
   of causal links between variables. The code used to produce the above
   image can be found [here](/post_resources/code/bidir_system.m).

2. **An example with unidirectional causality**. Now we consider
   the case where \\(\beta_{xy}=0\\) and \\(\beta_{yx}\\)
   is positive (\\(r_x\\) and \\(r_y\\) are comparable),
   so that only \\(X\\) "causes" \\(Y\\). Because the 
   signal for \\(X\\) influences the signal for \\(Y\\),
   we suspect that the shadow manifold for 
   \\(Y\\) should produce good predictions for \\(X\\)
   but not vice-versa. For a fixed \\(L\\), we produce
   scatter plots of the predicted vs observed 
   \\(X\\) and \\(Y\\) variables.

   <img src="/post_resources/images/asymmetric_coupling.png" 
   alt="assymetric coupling" width="100%" />

   We see that the predictions of \\(Y\\) using the 
   \\(X\\) shadow manifold have no skill while the 
   predictions of \\(X\\) using the shadow manifold of
   \\(Y\\) are pretty accurate. The code used for the
   unidirectional case can be found 
   [here](/post_resources/code/asym_system.m).
   	  
There are more examples with synthetic data in the 
paper. These demonstrate the CCM as applied to dynamical
systems with (1) synchrony (which confounds CCM
and can result in false positives of bidirectional
coupling), (2) external forcing of noncoupled variables,
and (3) more complex interacting networks.

#### CCM Style Analysis --- Real Data

There are a few reasons to suspect that CCM may have 
difficulty for real world data sets. In particular, 
real data sets can often have very few snapshots of the
dynamical system. If the shadow manifolds are high dimensional,
then it becomes difficult to resolve them with a
limited set of noisy data points (as an aside, certain neurological
data sets seem well suited to this situation, often containing
many measurements in time). The experiments of the
paper show that CCM can indeed be effective with
real data sets from ecology. 

Sugihara et al. apply the CCM methodology to 
a classical predator-prey data set (*Didinium*-*Paramecium* data).
You can download the original data set 
[here](/post_resources/data/veilleux.dat) and 
a version which can be loaded easily into MatLab
[here](/post_resources/data/vel-11a.dat) (this
version is needed to run the code below).
The experiment is essentially the same as that 
for the bidirectional coupling example above, except
that the shadow manifold dimension was chosen to be \\(m=3\\)
and the data is cleaned-up a bit. 

<img src="/post_resources/images/didinium_paramecium.png" 
   	  alt="bidirectional coupling" width="100%" />

The predictions of *Didinium* concentration using the
*Paramecium* shadow manifold (note: "*Paramecium* shadow
manifold" would be a great band name) converged
at a faster rate, suggesting that the *Didinium* signal
is stronger in the *Paramecium* time series than
the *Paramecium* signal in the *Didinium* time series. 
The code used to
generate the above plot can be found
[here](/post_resources/code/didinium_paramecium.m).

The paper also contains an interesting application of
CCM to sardine and anchovy populations. 
